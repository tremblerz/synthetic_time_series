{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1340ee-503d-4538-96a7-766bd7b51665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7be3f20-1669-479a-a4c8-3353cd57ad86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "sys.path.append(dirname('./synthcity/src/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1894a6-5cea-4c1e-88a9-ecd2df40445b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma7mo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f97c69-5212-488c-87a2-866957209901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b52757a1-4d54-4764-9666-4a1ceca1ee96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e525d301-f295-4083-95f2-53bbfba136c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4c644e-5d02-4fa6-9aba-72458133ca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "from synthcity.plugins import Plugins\n",
    "from synthcity.benchmark import Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653ee9b9-a2b6-4f96-949a-1daf76269980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timegan', 'fflows', 'timevae']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Plugins(categories=[\"time_series\"]).list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c46885-db3f-4d84-a3ca-b94a8b989eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from synthcity.utils.datasets.time_series.pbc import PBCDataloader\n",
    "from synthcity.utils.datasets.time_series.google_stocks import GoogleStocksDataloader\n",
    "from synthcity.plugins.core.dataloader import TimeSeriesDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064a33d7-36ab-4a66-a2f1-915024b80aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "static_data, temporal_data, horizons, outcome = GoogleStocksDataloader().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef065f6-9f3d-4e66-bb5e-af45b5c4acb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = TimeSeriesDataLoader(\n",
    "    temporal_data=temporal_data,\n",
    "    observation_times=horizons,\n",
    "    static_data=static_data,\n",
    "    outcome=outcome,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a470f3b-6207-47b4-921f-5a1b36448618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-29T11:43:40.469226-0400][20220][CRITICAL] module disabled: C:\\Users\\ma7mo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\generic\\plugin_goggle.py\n"
     ]
    }
   ],
   "source": [
    "syn_model_without_dp = Plugins().get(\"timegan\", dp_enabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc35756-3761-4d58-b321-8070164db7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-29T11:21:03.698570-0400][1524][CRITICAL] module disabled: C:\\Users\\ma7mo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\generic\\plugin_goggle.py\n",
      "[2023-08-29T11:21:03.698570-0400][1524][CRITICAL] module disabled: C:\\Users\\ma7mo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\generic\\plugin_goggle.py\n"
     ]
    }
   ],
   "source": [
    "new_model = Plugins().get(\"timegan\", mode=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982abc55-9ab7-4922-8e61-e14b0b6bceb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                             | 39/1000 [00:26<10:43,  1.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\plugin.py:244\u001b[0m, in \u001b[0;36mPlugin.fit\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress_context \u001b[38;5;241m=\u001b[39m load_from_file(bkp_file)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_schema \u001b[38;5;241m=\u001b[39m Schema(\n\u001b[0;32m    239\u001b[0m     data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    240\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy,\n\u001b[0;32m    241\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m    242\u001b[0m )\n\u001b[1;32m--> 244\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\time_series\\plugin_timegan.py:336\u001b[0m, in \u001b[0;36mTimeGANPlugin._fit\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m ImbalancedDatasetSampler(sampling_labels)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_model \u001b[38;5;241m=\u001b[39m TimeSeriesTabularGAN(\n\u001b[0;32m    297\u001b[0m     static_data\u001b[38;5;241m=\u001b[39mstatic,\n\u001b[0;32m    298\u001b[0m     temporal_data\u001b[38;5;241m=\u001b[39mtemporal,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    334\u001b[0m     dataloader_sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[0;32m    335\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Outcome generation\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcome_encoder\u001b[38;5;241m.\u001b[39mfit(outcome)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\models\\ts_tabular_gan.py:285\u001b[0m, in \u001b[0;36mTimeSeriesTabularGAN.fit\u001b[1;34m(self, static_data, temporal_data, observation_times, cond, encoded)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_encoded_columns \u001b[38;5;241m=\u001b[39m static_enc\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_encoded_columns \u001b[38;5;241m=\u001b[39m temporal_enc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemporal_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_times_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\models\\ts_gan.py:350\u001b[0m, in \u001b[0;36mTimeSeriesGAN.fit\u001b[1;34m(self, static_data, temporal_data, observation_times, cond)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    345\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting conditional with the same length as the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         )\n\u001b[0;32m    348\u001b[0m     condt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_tensor(cond)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_data_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemporal_data_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_times_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\models\\ts_gan.py:822\u001b[0m, in \u001b[0;36mTimeSeriesGAN._train\u001b[1;34m(self, static_data, temporal_data, observation_times, cond)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;66;03m# Train loop\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_n_iter)):\n\u001b[1;32m--> 822\u001b[0m     e_loss, g_loss, d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;66;03m# Check how the generator is doing by saving G's output on fixed_noise\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_print \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\models\\ts_gan.py:795\u001b[0m, in \u001b[0;36mTimeSeriesGAN._train_epoch\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    778\u001b[0m     E_losses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    779\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_embedding(\n\u001b[0;32m    780\u001b[0m             static_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    784\u001b[0m         )\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    786\u001b[0m     D_losses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    787\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_discriminator(\n\u001b[0;32m    788\u001b[0m             static_data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     )\n\u001b[0;32m    794\u001b[0m     G_losses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 795\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatic_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemporal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobservation_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m     )\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(E_losses), np\u001b[38;5;241m.\u001b[39mmean(G_losses), np\u001b[38;5;241m.\u001b[39mmean(D_losses)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\synthcity\\plugins\\core\\models\\ts_gan.py:694\u001b[0m, in \u001b[0;36mTimeSeriesGAN._train_epoch_generator\u001b[1;34m(self, static_data, temporal_data, observation_times, cond)\u001b[0m\n\u001b[0;32m    685\u001b[0m G_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    686\u001b[0m     errG_discrimination\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;241m+\u001b[39m errG_discrimination_horizons\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoments_penalty \u001b[38;5;241m*\u001b[39m errG_l1_moments\n\u001b[0;32m    691\u001b[0m )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Calculate gradients for G\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[43mG_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# Update G\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m train_models:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3285d5b-c23c-4340-87a6-903e4375ef9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<synthcity.plugins.time_series.plugin_timegan.TimeGANPlugin at 0x162eb365db0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_model_without_dp.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94bcd526-04ff-4dee-bced-d98b9fd19b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synth_data = syn_model_without_dp.generate(count=len(data)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49fa174f-66d8-49ee-8bca-c2b54f3fb020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_time_id</th>\n",
       "      <th>seq_temporal_Close</th>\n",
       "      <th>seq_temporal_High</th>\n",
       "      <th>seq_temporal_Low</th>\n",
       "      <th>seq_temporal_Open</th>\n",
       "      <th>seq_temporal_Volume</th>\n",
       "      <th>seq_out_Open_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992692</td>\n",
       "      <td>0.395024</td>\n",
       "      <td>0.356342</td>\n",
       "      <td>0.411729</td>\n",
       "      <td>0.372473</td>\n",
       "      <td>0.267372</td>\n",
       "      <td>0.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.947454</td>\n",
       "      <td>0.408647</td>\n",
       "      <td>0.360036</td>\n",
       "      <td>0.402173</td>\n",
       "      <td>0.373941</td>\n",
       "      <td>0.218904</td>\n",
       "      <td>0.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.949977</td>\n",
       "      <td>0.411638</td>\n",
       "      <td>0.353162</td>\n",
       "      <td>0.402652</td>\n",
       "      <td>0.369543</td>\n",
       "      <td>0.256489</td>\n",
       "      <td>0.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.948791</td>\n",
       "      <td>0.412320</td>\n",
       "      <td>0.349451</td>\n",
       "      <td>0.406865</td>\n",
       "      <td>0.376446</td>\n",
       "      <td>0.240710</td>\n",
       "      <td>0.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.433219</td>\n",
       "      <td>0.352305</td>\n",
       "      <td>0.410291</td>\n",
       "      <td>0.377639</td>\n",
       "      <td>0.215010</td>\n",
       "      <td>0.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>49</td>\n",
       "      <td>0.853573</td>\n",
       "      <td>0.420925</td>\n",
       "      <td>0.357470</td>\n",
       "      <td>0.404775</td>\n",
       "      <td>0.380247</td>\n",
       "      <td>0.189489</td>\n",
       "      <td>0.316911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>49</td>\n",
       "      <td>0.878370</td>\n",
       "      <td>0.424703</td>\n",
       "      <td>0.355659</td>\n",
       "      <td>0.416932</td>\n",
       "      <td>0.374426</td>\n",
       "      <td>0.208137</td>\n",
       "      <td>0.316911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>49</td>\n",
       "      <td>0.870931</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.388721</td>\n",
       "      <td>0.240522</td>\n",
       "      <td>0.316911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>49</td>\n",
       "      <td>0.873585</td>\n",
       "      <td>0.420702</td>\n",
       "      <td>0.371973</td>\n",
       "      <td>0.419031</td>\n",
       "      <td>0.200618</td>\n",
       "      <td>0.262444</td>\n",
       "      <td>0.316911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>49</td>\n",
       "      <td>0.919755</td>\n",
       "      <td>0.423914</td>\n",
       "      <td>0.369728</td>\n",
       "      <td>0.270268</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>0.271796</td>\n",
       "      <td>0.316911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_id  seq_time_id  seq_temporal_Close  seq_temporal_High  \\\n",
       "0         0     0.992692            0.395024           0.356342   \n",
       "1         0     0.947454            0.408647           0.360036   \n",
       "2         0     0.949977            0.411638           0.353162   \n",
       "3         0     0.948791            0.412320           0.349451   \n",
       "4         0     0.893649            0.433219           0.352305   \n",
       "..      ...          ...                 ...                ...   \n",
       "495      49     0.853573            0.420925           0.357470   \n",
       "496      49     0.878370            0.424703           0.355659   \n",
       "497      49     0.870931            0.412096           0.366250   \n",
       "498      49     0.873585            0.420702           0.371973   \n",
       "499      49     0.919755            0.423914           0.369728   \n",
       "\n",
       "     seq_temporal_Low  seq_temporal_Open  seq_temporal_Volume  \\\n",
       "0            0.411729           0.372473             0.267372   \n",
       "1            0.402173           0.373941             0.218904   \n",
       "2            0.402652           0.369543             0.256489   \n",
       "3            0.406865           0.376446             0.240710   \n",
       "4            0.410291           0.377639             0.215010   \n",
       "..                ...                ...                  ...   \n",
       "495          0.404775           0.380247             0.189489   \n",
       "496          0.416932           0.374426             0.208137   \n",
       "497          0.414209           0.388721             0.240522   \n",
       "498          0.419031           0.200618             0.262444   \n",
       "499          0.270268           0.375605             0.271796   \n",
       "\n",
       "     seq_out_Open_next  \n",
       "0             0.316910  \n",
       "1             0.316910  \n",
       "2             0.316910  \n",
       "3             0.316910  \n",
       "4             0.316910  \n",
       "..                 ...  \n",
       "495           0.316911  \n",
       "496           0.316911  \n",
       "497           0.316911  \n",
       "498           0.316911  \n",
       "499           0.316911  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a84a505-3068-4d82-aed8-011ae5b6f58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequence(dataset, seq_len):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for index in range(0, len(dataset)//seq_len): # Selecting 50 rows at a time\n",
    "        sequences.append(dataset.iloc[index*seq_len:(index+1)*seq_len-1])\n",
    "        labels.append(dataset.iloc[(index+1)*seq_len-1][2])\n",
    "    return (np.array(sequences),np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b52b35ec-5016-42b1-966e-5b8a1b8618f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, dropout,\n",
    "                 input_dim=8, num_classes = 1, hidden_size = 1, **kwargs):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        print(\"==> not used params in network class:\", kwargs.keys())\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = dropout\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "\n",
    "        # Main part of the network\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.lstm_layers.append(nn.LSTM(input_size=input_dim,hidden_size=self.hidden_size))\n",
    "        self.lstm_layers.append(nn.Dropout(p=dropout))\n",
    "        self.lstm_layers.append(nn.LSTM(input_size=self.hidden_size,\n",
    "                           hidden_size=self.hidden_size))\n",
    "        self.lstm_layers.append(nn.Dropout(p=dropout))\n",
    "        self.lstm_layers.append(nn.LSTM(input_size=self.hidden_size,\n",
    "                           hidden_size=self.hidden_size))\n",
    "        self.lstm_layers.append(nn.Dropout(p=dropout))\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(self.hidden_size, num_classes)\n",
    "        # self.output_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input layer\n",
    "        X = X.to(torch.float32)\n",
    "        mX = X\n",
    "        # Main part of the network\n",
    "        i = 0\n",
    "        for lstm in self.lstm_layers:\n",
    "            if i % 2 == 0:\n",
    "                output, _ = lstm(mX)\n",
    "            else:\n",
    "                output = lstm(mX)\n",
    "            mX = output\n",
    "            i += 1\n",
    "        L = output[:, -1, :]\n",
    "        # Output layer\n",
    "        y = self.output_layer(L)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3661e53-b843-49c6-82fe-28e716b0acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> not used params in network class: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "model = Network(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "814569f8-aa50-40ac-bf14-e968aad63a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer_config = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40f7f6b7-aa93-49f3-a23a-51f77ed88b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = create_sequence(data.dataframe(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0bf6be23-8db5-4cbd-a242-cc6aae852f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synth_X, synth_y = create_sequence(synth_data.dataframe(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a86fc7e1-2284-4f09-904c-c7cb35f52f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "505d12fe-f272-48c3-964c-d283f4aa601a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=1)\n",
    "val_loader = DataLoader(list(zip(X_test, y_test)), batch_size=1, shuffle=True)\n",
    "optimizer = optimizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4b4e09-0a16-4838-9bd6-cafb746b8452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [33/33], Validation Batch Loss: 0.1087\n",
      "Epoch [2/100], Step [33/33], Validation Batch Loss: 0.0921\n",
      "Epoch [3/100], Step [33/33], Validation Batch Loss: 0.0782\n",
      "Epoch [4/100], Step [33/33], Validation Batch Loss: 0.0674\n",
      "Epoch [5/100], Step [33/33], Validation Batch Loss: 0.0587\n",
      "Epoch [6/100], Step [33/33], Validation Batch Loss: 0.0523\n",
      "Epoch [7/100], Step [33/33], Validation Batch Loss: 0.0473\n",
      "Epoch [8/100], Step [33/33], Validation Batch Loss: 0.0437\n",
      "Epoch [9/100], Step [33/33], Validation Batch Loss: 0.0412\n",
      "Epoch [10/100], Step [33/33], Validation Batch Loss: 0.0395\n",
      "Epoch [11/100], Step [33/33], Validation Batch Loss: 0.0386\n",
      "Epoch [12/100], Step [33/33], Validation Batch Loss: 0.0381\n",
      "Epoch [13/100], Step [33/33], Validation Batch Loss: 0.0381\n",
      "Epoch [14/100], Step [33/33], Validation Batch Loss: 0.0384\n",
      "Epoch [15/100], Step [33/33], Validation Batch Loss: 0.0388\n",
      "Epoch [16/100], Step [33/33], Validation Batch Loss: 0.0394\n",
      "Epoch [17/100], Step [33/33], Validation Batch Loss: 0.0401\n",
      "Epoch [18/100], Step [33/33], Validation Batch Loss: 0.0408\n",
      "Epoch [19/100], Step [33/33], Validation Batch Loss: 0.0416\n",
      "Epoch [20/100], Step [33/33], Validation Batch Loss: 0.0423\n",
      "Epoch [21/100], Step [33/33], Validation Batch Loss: 0.0429\n",
      "Epoch [22/100], Step [33/33], Validation Batch Loss: 0.0435\n",
      "Epoch [23/100], Step [33/33], Validation Batch Loss: 0.0441\n",
      "Epoch [24/100], Step [33/33], Validation Batch Loss: 0.0447\n",
      "Epoch [25/100], Step [33/33], Validation Batch Loss: 0.0452\n",
      "Epoch [26/100], Step [33/33], Validation Batch Loss: 0.0456\n",
      "Epoch [27/100], Step [33/33], Validation Batch Loss: 0.0461\n",
      "Epoch [28/100], Step [33/33], Validation Batch Loss: 0.0465\n",
      "Epoch [29/100], Step [33/33], Validation Batch Loss: 0.0468\n",
      "Epoch [30/100], Step [33/33], Validation Batch Loss: 0.0471\n",
      "Epoch [31/100], Step [33/33], Validation Batch Loss: 0.0474\n",
      "Epoch [32/100], Step [33/33], Validation Batch Loss: 0.0476\n",
      "Epoch [33/100], Step [33/33], Validation Batch Loss: 0.0477\n",
      "Epoch [34/100], Step [33/33], Validation Batch Loss: 0.0479\n",
      "Epoch [35/100], Step [33/33], Validation Batch Loss: 0.0480\n",
      "Epoch [36/100], Step [33/33], Validation Batch Loss: 0.0481\n",
      "Epoch [37/100], Step [33/33], Validation Batch Loss: 0.0482\n",
      "Epoch [38/100], Step [33/33], Validation Batch Loss: 0.0482\n",
      "Epoch [39/100], Step [33/33], Validation Batch Loss: 0.0484\n",
      "Epoch [40/100], Step [33/33], Validation Batch Loss: 0.0484\n",
      "Epoch [41/100], Step [33/33], Validation Batch Loss: 0.0484\n",
      "Epoch [42/100], Step [33/33], Validation Batch Loss: 0.0484\n",
      "Epoch [43/100], Step [33/33], Validation Batch Loss: 0.0485\n",
      "Epoch [44/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [45/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [46/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [47/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [48/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [49/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [50/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [51/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [52/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [53/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [54/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [55/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [56/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [57/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [58/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [59/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [60/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [61/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [62/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [63/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [64/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [65/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [66/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [67/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [68/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [69/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [70/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [71/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [72/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [73/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [74/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [75/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [76/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [77/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [78/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [79/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [80/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [81/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [82/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [83/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [84/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [85/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [86/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [87/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [88/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [89/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [90/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [91/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [92/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [93/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [94/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [95/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [96/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [97/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [98/100], Step [33/33], Validation Batch Loss: 0.0487\n",
      "Epoch [99/100], Step [33/33], Validation Batch Loss: 0.0486\n",
      "Epoch [100/100], Step [33/33], Validation Batch Loss: 0.0486\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.reshape(tuple(outputs.shape))\n",
    "            targets = targets.to(torch.float32)\n",
    "            batch_loss = loss(outputs, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            num_batches = 0\n",
    "            res = {}\n",
    "            y_true = []\n",
    "            predictions = []\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.reshape(tuple(outputs.shape))\n",
    "                targets = targets.to(torch.float32)\n",
    "                batch_loss = loss(outputs, targets)\n",
    "                val_loss += batch_loss.item()\n",
    "                num_batches += 1\n",
    "            val_loss /= num_batches\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Validation Batch Loss: {:.4f}'\n",
    "                    .format(epoch + 1, 100, i + 1, len(train_loader), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c06d224f-30eb-419c-a29b-148e33d09147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> not used params in network class: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "synth_model = Network(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0ad15d0-ae3c-4d30-9e4c-e17e70c597bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer_config = optim.Adam(synth_model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5949284d-2411-48b0-ac4e-2719c75ef1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(list(zip(synth_X, synth_y)), batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(list(zip(X_test, y_test)), batch_size=1)\n",
    "optimizer = optimizer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "43a0a196-9d68-438a-a8f1-7f2548b4a3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [50/50], Validation Batch Loss: 0.2965\n",
      "Epoch [2/100], Step [50/50], Validation Batch Loss: 0.2411\n",
      "Epoch [3/100], Step [50/50], Validation Batch Loss: 0.1967\n",
      "Epoch [4/100], Step [50/50], Validation Batch Loss: 0.1637\n",
      "Epoch [5/100], Step [50/50], Validation Batch Loss: 0.1356\n",
      "Epoch [6/100], Step [50/50], Validation Batch Loss: 0.1135\n",
      "Epoch [7/100], Step [50/50], Validation Batch Loss: 0.0958\n",
      "Epoch [8/100], Step [50/50], Validation Batch Loss: 0.0815\n",
      "Epoch [9/100], Step [50/50], Validation Batch Loss: 0.0722\n",
      "Epoch [10/100], Step [50/50], Validation Batch Loss: 0.0645\n",
      "Epoch [11/100], Step [50/50], Validation Batch Loss: 0.0583\n",
      "Epoch [12/100], Step [50/50], Validation Batch Loss: 0.0536\n",
      "Epoch [13/100], Step [50/50], Validation Batch Loss: 0.0505\n",
      "Epoch [14/100], Step [50/50], Validation Batch Loss: 0.0486\n",
      "Epoch [15/100], Step [50/50], Validation Batch Loss: 0.0475\n",
      "Epoch [16/100], Step [50/50], Validation Batch Loss: 0.0461\n",
      "Epoch [17/100], Step [50/50], Validation Batch Loss: 0.0454\n",
      "Epoch [18/100], Step [50/50], Validation Batch Loss: 0.0452\n",
      "Epoch [19/100], Step [50/50], Validation Batch Loss: 0.0453\n",
      "Epoch [20/100], Step [50/50], Validation Batch Loss: 0.0446\n",
      "Epoch [21/100], Step [50/50], Validation Batch Loss: 0.0440\n",
      "Epoch [22/100], Step [50/50], Validation Batch Loss: 0.0444\n",
      "Epoch [23/100], Step [50/50], Validation Batch Loss: 0.0443\n",
      "Epoch [24/100], Step [50/50], Validation Batch Loss: 0.0438\n",
      "Epoch [25/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [26/100], Step [50/50], Validation Batch Loss: 0.0441\n",
      "Epoch [27/100], Step [50/50], Validation Batch Loss: 0.0439\n",
      "Epoch [28/100], Step [50/50], Validation Batch Loss: 0.0435\n",
      "Epoch [29/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [30/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [31/100], Step [50/50], Validation Batch Loss: 0.0423\n",
      "Epoch [32/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [33/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [34/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [35/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [36/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [37/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [38/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [39/100], Step [50/50], Validation Batch Loss: 0.0436\n",
      "Epoch [40/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [41/100], Step [50/50], Validation Batch Loss: 0.0428\n",
      "Epoch [42/100], Step [50/50], Validation Batch Loss: 0.0435\n",
      "Epoch [43/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [44/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [45/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [46/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [47/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [48/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [49/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [50/100], Step [50/50], Validation Batch Loss: 0.0437\n",
      "Epoch [51/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [52/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [53/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [54/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [55/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [56/100], Step [50/50], Validation Batch Loss: 0.0435\n",
      "Epoch [57/100], Step [50/50], Validation Batch Loss: 0.0439\n",
      "Epoch [58/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [59/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [60/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [61/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [62/100], Step [50/50], Validation Batch Loss: 0.0426\n",
      "Epoch [63/100], Step [50/50], Validation Batch Loss: 0.0428\n",
      "Epoch [64/100], Step [50/50], Validation Batch Loss: 0.0425\n",
      "Epoch [65/100], Step [50/50], Validation Batch Loss: 0.0428\n",
      "Epoch [66/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [67/100], Step [50/50], Validation Batch Loss: 0.0434\n",
      "Epoch [68/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [69/100], Step [50/50], Validation Batch Loss: 0.0428\n",
      "Epoch [70/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [71/100], Step [50/50], Validation Batch Loss: 0.0427\n",
      "Epoch [72/100], Step [50/50], Validation Batch Loss: 0.0425\n",
      "Epoch [73/100], Step [50/50], Validation Batch Loss: 0.0426\n",
      "Epoch [74/100], Step [50/50], Validation Batch Loss: 0.0431\n",
      "Epoch [75/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [76/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [77/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [78/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [79/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [80/100], Step [50/50], Validation Batch Loss: 0.0427\n",
      "Epoch [81/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [82/100], Step [50/50], Validation Batch Loss: 0.0426\n",
      "Epoch [83/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [84/100], Step [50/50], Validation Batch Loss: 0.0428\n",
      "Epoch [85/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [86/100], Step [50/50], Validation Batch Loss: 0.0430\n",
      "Epoch [87/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [88/100], Step [50/50], Validation Batch Loss: 0.0426\n",
      "Epoch [89/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [90/100], Step [50/50], Validation Batch Loss: 0.0433\n",
      "Epoch [91/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [92/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [93/100], Step [50/50], Validation Batch Loss: 0.0425\n",
      "Epoch [94/100], Step [50/50], Validation Batch Loss: 0.0427\n",
      "Epoch [95/100], Step [50/50], Validation Batch Loss: 0.0425\n",
      "Epoch [96/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [97/100], Step [50/50], Validation Batch Loss: 0.0432\n",
      "Epoch [98/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [99/100], Step [50/50], Validation Batch Loss: 0.0429\n",
      "Epoch [100/100], Step [50/50], Validation Batch Loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):\n",
    "        synth_model.train()\n",
    "        running_loss = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            outputs = synth_model(inputs)\n",
    "            targets = targets.reshape(tuple(outputs.shape))\n",
    "            targets = targets.to(torch.float32)\n",
    "            batch_loss = loss(outputs, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        synth_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            num_batches = 0\n",
    "            res = {}\n",
    "            y_true = []\n",
    "            predictions = []\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                outputs = synth_model(inputs)\n",
    "                targets = targets.reshape(tuple(outputs.shape))\n",
    "                targets = targets.to(torch.float32)\n",
    "                batch_loss = loss(outputs, targets)\n",
    "                val_loss += batch_loss.item()\n",
    "                num_batches += 1\n",
    "            val_loss /= num_batches\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Validation Batch Loss: {:.4f}'\n",
    "                    .format(epoch + 1, 100, i + 1, len(train_loader), val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a0bd9-6370-4df2-ae00-ace9467e644a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
